{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55e42b6-38b1-495c-be3f-a3adb4ba71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d924867f-0a30-4dee-843a-9d02864eb9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImages/Cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                     | 193/12501 [00:00<00:12, 984.39it/s]Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      " 26%|█████████▍                          | 3276/12501 [00:03<00:08, 1052.89it/s]Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      " 54%|███████████████████▌                | 6783/12501 [00:06<00:05, 1110.78it/s]Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      " 63%|██████████████████████▊             | 7917/12501 [00:07<00:04, 1078.82it/s]Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      " 75%|███████████████████████████▏        | 9424/12501 [00:08<00:02, 1227.70it/s]Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "100%|███████████████████████████████████| 12501/12501 [00:11<00:00, 1123.14it/s]\n",
      "/home/siddharth/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat:  12476\n",
      "dog:  0\n",
      "PetImages/Dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▌                                 | 1192/12501 [00:01<00:12, 930.58it/s]Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      " 11%|████▏                                | 1405/12501 [00:01<00:11, 995.20it/s]Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      " 16%|█████▉                               | 2016/12501 [00:02<00:10, 979.29it/s]Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      " 33%|███████████▋                        | 4071/12501 [00:04<00:08, 1043.53it/s]Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      " 57%|█████████████████████                | 7125/12501 [00:07<00:05, 978.55it/s]Warning: unknown JFIF revision number 0.00\n",
      " 79%|█████████████████████████████▏       | 9867/12501 [00:09<00:02, 993.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m REBUILD_DATA:\n\u001b[1;32m     38\u001b[0m     dogvcat \u001b[38;5;241m=\u001b[39m Dvc()\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mdogvcat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mDvc.make_training_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# print(label)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(label, file)\n\u001b[0;32m---> 20\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIMG_SIZE, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIMG_SIZE))\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_data\u001b[38;5;241m.\u001b[39mappend([np\u001b[38;5;241m.\u001b[39marray(img), np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLABELS[label]]])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = True\n",
    " \n",
    "    \n",
    "class Dvc():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = 'PetImages/Cat'\n",
    "    DOGS = 'PetImages/Dog'\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for file in tqdm(os.listdir(label)):\n",
    "                try:\n",
    "                    # print(label)\n",
    "                    path = os.path.join(label, file)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            \n",
    "            np.random.shuffle(self.training_data)\n",
    "            np.save('training_data.npy', self.training_data)\n",
    "            print(\"cat: \", self.catcount)\n",
    "            print(\"dog: \", self.dogcount)\n",
    "            \n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogvcat = Dvc()\n",
    "    dogvcat.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3046cefe-fa0e-481e-b0b4-975443dc4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = np.load(\"training_data.npy\",allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebea16f-f849-460c-9de2-c8b0455ed966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 97, 123, 221, ..., 121, 120, 110],\n",
       "              [138, 239, 246, ..., 127, 123, 116],\n",
       "              [201, 241, 249, ..., 121, 123, 120],\n",
       "              ...,\n",
       "              [103, 140,  87, ..., 208, 202, 136],\n",
       "              [127, 109, 118, ..., 122,  74, 126],\n",
       "              [104, 126, 105, ...,  63, 122, 106]], dtype=uint8),\n",
       "       array([0., 1.])], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0034c215-1f4e-4cfc-ac39-10044454496d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f520a6b91e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(td[2][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5598ca-e325-4c70-a0b6-570a72ecb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.pool3 = nn.MaxPool2d((2, 2))\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.flatten(start_dim=1) # print(x.shape) to put the value in self.fc1()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c78c79e-e172-4cda-b8b8-64d87cba6d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5194, 0.4806]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.forward(torch.randn(1, 1, 50, 50)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2e5e015-e76d-41a2-9d3a-16ab5edeccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120961/1490855746.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  X = torch.Tensor([i[0] for i in td]).view(-1, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in td]).view(-1, 50, 50)\n",
    "X = X/255.0 # rescaling image\n",
    "\n",
    "y = torch.Tensor([i[1] for i in td])\n",
    "\n",
    "val_percent = 0.1\n",
    "val_size = int(len(X)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b3b8ba-04ee-4f41-975d-7faeadab4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_x = X[-val_size:]\n",
    "test_y  = y[-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82cb8eff-5c35-4a7b-a582-c47a69cf4a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11229"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31cd408d-3a52-4cc0-b9bc-214caf99091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:14<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:11<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:13<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:13<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:14<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:13<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 113/113 [00:12<00:00,  9.05it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 7\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in tqdm(range(0, len(train_x), BATCH_SIZE)):\n",
    "        batch_x = train_x[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i: i+BATCH_SIZE]\n",
    "        net.zero_grad()\n",
    "        outputs = net(batch_x)\n",
    "        loss_ = loss(outputs, batch_y)\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d887581-6abe-4135-aab9-b02fc090bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1247/1247 [00:00<00:00, 1424.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_x))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_x[i].view(-1, 1, 50, 50))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        \n",
    "        total += 1\n",
    "        \n",
    "print(f\"Accuracy : {round(correct/total, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45925590-d0b6-4292-9f8a-42ffa7d484f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n",
      "12470\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "import os\n",
    "files = os.listdir('PetImages/Dog')\n",
    "for i in files:\n",
    "    img = cv2.imread(f'PetImages/Dog/{i}')\n",
    "    try:\n",
    "        img = cv2.resize(img, (50, 50))\n",
    "        # img = np.array(img)\n",
    "        img = torch.Tensor(img)\n",
    "        with torch.no_grad():\n",
    "            net_out = net(img.view(-1, 1, 50, 50))[0]\n",
    "            predicted_class = torch.argmax(net_out)\n",
    "            if predicted_class == 0:\n",
    "                # print(\"Cat\")\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    except:\n",
    "        pass\n",
    "print(correct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c57ae7c-1b96-47d7-9cc7-595c4605e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train=False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss_ = loss(outputs, y)\n",
    "    if train:\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return acc, loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8db6451-8ed9-4200-853e-8d7913b78b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(size=32):\n",
    "    random_start = np.random.randint(len(test_x)-size)\n",
    "    X, y = test_x[random_start:random_start+size], test_y[random_start:random_start+size]\n",
    "    with torch.no_grad():\n",
    "      val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50), y)\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a6defe2-e40f-4b75-8742-6c2a4c4869dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "val_acc, val_loss = test()\n",
    "print(val_acc, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2dd195-7448-4a48-b677-b0b17e9afdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd630c-9a92-494f-809c-7173b11ff3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
